import os
import cv2
import face_recognition
import mediapipe as mp
import numpy as np

def process_face_image(image_path: str):
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
    if not os.path.exists(image_path):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û: {image_path}")
        return

    # ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB
    frame = cv2.imread(image_path)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
    known_encodings = []
    known_names = []

    known_faces_dir = os.path.join(os.path.dirname(__file__), "known_faces")
    if not os.path.exists(known_faces_dir):
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'known_faces'")
    else:
        for filename in os.listdir(known_faces_dir):
            if filename.endswith(".jpg"):
                print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î: {filename}")
                image = face_recognition.load_image_file(os.path.join(known_faces_dir, filename))
                encodings = face_recognition.face_encodings(image)
                if encodings:
                    known_encodings.append(encodings[0])
                    known_names.append(os.path.splitext(filename)[0])

    # ‡πÉ‡∏ä‡πâ MediaPipe ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    mp_face_detection = mp.solutions.face_detection
    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as detector:
        result = detector.process(rgb)

        if result.detections:
            for det in result.detections:
                bbox = det.location_data.relative_bounding_box
                h, w, _ = frame.shape
                x1 = int(bbox.xmin * w)
                y1 = int(bbox.ymin * h)
                x2 = int((bbox.xmin + bbox.width) * w)
                y2 = int((bbox.ymin + bbox.height) * h)

                # ‡∏Ñ‡∏£‡∏≠‡∏õ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ encoding
                face_crop = rgb[y1:y2, x1:x2]
                face_encoding = face_recognition.face_encodings(face_crop)

                if face_encoding:
                    matches = face_recognition.compare_faces(known_encodings, face_encoding[0])
                    face_distances = face_recognition.face_distance(known_encodings, face_encoding[0])
                    best_match_index = np.argmin(face_distances)

                    name = "Unknown"
                    if matches and matches[best_match_index]:
                        name = known_names[best_match_index]

                    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                    
                    return name
                else:
                    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö encoding ‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤")
                    return name
        else:
            print("üòï ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û")

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    cv2.imshow("Result", frame)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    return None
